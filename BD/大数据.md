
## 安装
1. linux下，如果不知道java安装目录，`echo $JAVA_HOME`。
2. windows下
   - 第一步，etc/hadoop/hadoop-env.cmd文件进行编辑，将`set JAVA_HOME=%JAVA_HOME%`改成`set JAVA_HOME=C:"\Program Files"\Java\jdk1.8.0_191`,然后才能在shell下执行bin/hadoop。这里有几个问题：
     - Windows下跟linux不同，linux也许是etc/hadoop/hadoop-env.sh，但是Windows下是etc/hadoop/hadoop-env.cmd文件。
     - 由于我的java装在C:\Program Files下，但是Program Files文件夹有空格，因此报错。解决：有几种方式，一种给Program Files加引号，或者改为C:\PROGRA~1
   - 第二步，运行实例，复制解压缩的conf目录以用作输入，然后查找并显示给定正则表达式的每个匹配项，输出将写入给定的输出目录。就是通过Hadoop做一个大数据的查找功能。不过应该会报错：
      - 显示缺执行文件`java.io.FileNotFoundException: Could not locate Hadoop executable:`根据[提示](https://wiki.apache.org/hadoop/WindowsProblems)在该网页的指定位置下载winutils.exe，不过GitHub没有3.2.0的，我发现3.0.0也可以用。下载后放在自定义的位置，然后在自己电脑的环境变量中设置HADOOP_HOME的值为刚刚下载的winutils位置。
      - 解决完上面问题，报另外的错：
## 基本概念
1. 数据采集之后，该如何存储？HDFS，TFS等分布式文件存储系统
2. HDFS，按数据块存储，数据块作为一个抽象块而不是整个文件作为基本单元，默认大小64M：
   - NameNode:主节点。一个NameNode，多个DataNode。
      - 管理文件系统的命名空间，存放文件元数据
      - 维护文件系统的所有文件和目录，文件与数据块的映射
      - 记录着每个文件中各个块所在的数据节点的信息。
   - DataNode：从节点。
      - 存储并检索数据块
      - 向NameNode更新所存储块的列表
        >HDFS不适合大量小文件存储、不适合并发写入、不支持文件随机修改、不支持随机读等低延时的访问方式。
   - HDFS写流程：
      - 客户端向NameNode发起写数据请求。分块写入DataNode节点，DataNode自动完成副本备份。DataNode向NameNode汇报存储完成，NameNode通知客户端。
   - HDFS读流程：
      - 客户端向NameNode发起数据请求。
      - NameNode找出距离最近的DataNode节点信息，客户端从DataNode分块下载文件。
      
      
3. HDFS常用命令：
   - copyFromLocal从本地拷贝到HDFS文件系统.类似的copyToLocal.
   - get下载文件，put上传文件。
