
## 安装
1. linux下，如果不知道java安装目录，`echo $JAVA_HOME`。
2. windows下可以[参考](http://www.cnblogs.com/chevin/p/9090683.html)
   - 第一步，etc/hadoop/hadoop-env.cmd文件进行编辑，将`set JAVA_HOME=%JAVA_HOME%`改成`set JAVA_HOME=C:"\Program Files"\Java\jdk1.8.0_191`,然后才能在shell下执行bin/hadoop。这里有几个问题：
     - Windows下跟linux不同，linux也许是etc/hadoop/hadoop-env.sh，但是Windows下是etc/hadoop/hadoop-env.cmd文件。
     - 由于我的java装在C:\Program Files下，但是Program Files文件夹有空格，因此报错。解决：有几种方式，一种给Program Files加引号，或者改为C:\PROGRA~1
   - 第二步，独立操作，复制解压缩的conf目录以用作输入，然后查找并显示给定正则表达式的每个匹配项，输出将写入给定的输出目录。就是通过Hadoop做一个大数据的查找功能。不过应该会报错：
      - 显示缺执行文件`java.io.FileNotFoundException: Could not locate Hadoop executable:`根据[提示](https://wiki.apache.org/hadoop/WindowsProblems)在该网页的指定位置下载winutils.exe以及hadoop.dll，放在hadoop目录的bin下。至于要不要设置hadoop的环境变量，如果这样还不行就设置一下。不过GitHub没有3.2.0的，我发现[3.1.0](https://github.com/s911415/apache-hadoop-3.1.0-winutils)也可以用，但是3.0.0不能。不用在C:/Windows/System32文件夹下也拷贝一个hadoop.dll（我看好多网页上要加这个，我没加也顺利运行）。

## 基本概念
1. 数据采集之后，该如何存储？HDFS，TFS等分布式文件存储系统.HDFS适用于一次写入多次查询的情况，不支持并发写情况，小文件不合适。
2. HDFS，按数据块存储，数据块作为一个抽象块而不是整个文件作为基本单元，默认大小64M：
   - NameNode:主节点。一个NameNode，多个DataNode。
      - 管理文件系统的命名空间，存放文件元数据
      - 维护文件系统的所有文件和目录，文件与数据块的映射
      - 记录着每个文件中各个块所在的数据节点的信息。
   - DataNode：从节点。
      - 存储并检索数据块
      - 向NameNode更新所存储块的列表
        >HDFS不适合大量小文件存储、不适合并发写入、不支持文件随机修改、不支持随机读等低延时的访问方式。
   - [HDFS写流程](https://www.cnblogs.com/LeonNew/p/5489462.html)：
      - 初始化FileSystem。客户端向NameNode发起写数据请求，客户端调用create()来创建文件
      - FileSystem用RPC调用元数据节点，在文件系统的命名空间中创建一个新的文件，元数据节点首先确定文件原来不存在，并且客户端有创建文件的权限，然后创建新文件。然后返回DFSOutputStream，用于客户端写数据。
      - client写入数据时，DFSOutputStream将数据分成一个个的包，写入内部队列，称为数据队列data queue。数据流Data Streamer负责处理数据队列，根据适合的DataNode的列表要求NameNode分配适合的新块来存储数据副本。然后将分配的DataNode放在一个pipeline里，Data Streamer将数据块写入pipeline中的第一个数据节点，第一个数据节点将数据块发送给第二个数据节点，第二个数据节点将数据发送给第三个数据节点。
      - DFSOutputStream内部存在确认队列ack queue，等待pipeline中的DataNode告知数据已经写入成功。
      
                FileSystem fs=null;

                @Before
                public void init() throws Exception{
                     fs= FileSystem.get(new URI("hdfs://hadoop01:9000"),new Configuration(),"root");
                }

                @Test
                public void testUpLoad() throws Exception{
                     OutputStream out = fs.create(new Path("/Xshellqqq"));//发起写请求
                     InputStream in = new FileInputStream(new File("c:/Xshell-5.0.1337p.exe"));//将本地文件写入流
                     IOUtils.copyBytes(in, out, 4096, true);//将文件流in写入out后，即上面第三步开始执行
                }

                @Test
                public void testCopyFromLocalFile() throws IllegalArgumentException, IOException{
                     fs.copyFromLocalFile(new Path("c:/Xshell-5.0.1337p.exe"), new Path("/1132/Xshellaaa"));
                }
   - HDFS读流程：
      - 初始化FileSystem.
      - 客户端向NameNode发起数据请求,即客户端(client)用FileSystem的open()函数打开文件
      - FileSystem用RPC调用元数据节点，得到文件的数据块信息，对于每一个数据块，元数据节点返回保存数据块的数据节点的地址。
      - FileSystem返回FSDataInputStream给客户端，用来读取数据，客户端调用stream的read()函数开始读取数据。
      - 而DFSInputStream连接保存此文件第一个数据块的最近的数据节点，data从数据节点读到客户端(client)。即NameNode找出距离最近的DataNode节点信息，客户端从DataNode分块下载文件。
      - 当此数据块读取完毕时，DFSInputStream关闭和此数据节点的连接，然后连接此文件下一个数据块的最近的数据节点。
      
                public static void main(String[] args) throws Exception {
                  
                  FileSystem fs = FileSystem.get(new URI("hdfs://hadoop01:9000"),new Configuration());
                  InputStream in = fs.open(new Path("/dianying.mp4"));  //open后，FileSystem返回FSDataInputStream给客户端
                  OutputStream out = new  FileOutputStream(new File("c:/dianying.mp4"));//客户端自己新建一个输出流用于接收服务器的数据
                  IOUtils.copyBytes(in, out, 4096, true);		
               }
      
      
3. HDFS常用命令：
   - copyFromLocal从本地拷贝到HDFS文件系统.类似的copyToLocal.
   - get下载文件，put上传文件。
4. MapReduce(分布式计算系统)
   - MapReduce是处理数据的编程模型。
   - MapReduce分为两个阶段，map阶段和reduce阶段，map阶段将原始数据进行过滤操作，以键/值对的方式输出，map阶段的输出是reduce阶段的输入，reduce阶段对数据处理后输出最终的结果。
   - MapReduce处理的数据文件保存在HDFS上，并且最终的计算结果同样会保存到HDFS上。
5. [早期MapReduce](https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/),由一个JobTracker和多个TaskTracker组成
   - 首先用户程序 (JobClient) 提交了一个 job，job 的信息会发送到 Job Tracker 中，Job Tracker 是 Map-reduce 框架的中心，他需要与集群中的机器定时通信 (heartbeat), 需要管理哪些程序应该跑在哪些机器上，需要管理所有 job 失败、重启等操作。
   - TaskTracker 是 Map-reduce 集群中每台机器都有的一个部分，他做的事情主要是监视自己所在机器的资源情况。
   - 流程：TaskTracker执行JobTracker指定的任务。当一个Job(数据分析作业)提交时，JobTracker接收到提交的任作业后，将作业执行需要的配置信息和其他数据信息分发给相应的TaskTracker。同时要调度任务并监控TaskTracker的执行。
6. [YARN](https://github.com/sunnyandgood/BigData/blob/master/HDFS/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0.md)(分布式计算系统)
   - YARN将JobTracker分为两个组件：ResourceManager和ApplicationMaster。
   - ResourceManager进程运行在主节点上，作为集群资源的管理者和总调度，不在需要关心应用程序的执行和监控。ApplicationMaster进程运行在从节点上，主要管理应用程序的执行和应用程序的生命周期，当应用程序执行结束，ApplicationMaster的生命周期结束。
   - 客户端发出应用程序执行请求，ResourceManager会创建与应用程序对应的ApplicationMaster实例。
   
7. [mapReduce](https://github.com/sunnyandgood/BigData/blob/master/MapReduce/MapReduce%E5%8E%9F%E7%90%86.md)
8. [Partitioner](https://www.jianshu.com/p/0f85d9688ebe)编程:就是将map的输出找reducer。将mapper（如果使用了combiner的话就是combiner）输出的key/value拆分为分片（shard），每个reducer对应一个分片。默认情况下，MR调用Hashpartitioner类，如果程序员编写了自己的partition类，那么就使用自己编写的partition编程进行数据分，以达到map阶段的数据分区切片，从而防止reduce阶段的数据倾斜问题，实现负载均衡。
8. [Combiner](https://www.cnblogs.com/edisonchou/p/4297786.html)编程
   - Combiner最基本是实现本地key的聚合，对map输出的key排序，value进行迭代。

           map: (K1, V1) → list(K2, V2) 
           combine: (K2, list(V2)) → list(K2, V2) 
           reduce: (K2, list(V2)) → list(K3, V3)
   - Combiner还有本地reduce功能（其本质上就是一个reduce），例如Hadoop自带的wordcount的例子和找出value的最大值的程序，combiner和reduce完全一致，如下所示：
   
          map: (K1, V1) → list(K2, V2) 
          combine: (K2, list(V2)) → list(K3, V3) 
          reduce: (K3, list(V3)) → list(K4, V4)
9. [zookeeper](https://www.cnblogs.com/ultranms/p/9585191.html)
   - 功能：
     - 配置管理
     - 名字服务。类似于ip与域名的映射，当服务多的时候，名字服务提供：‘服务地址’与‘用户都熟知的访问点’之间的映射。
     - 分布式锁。共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。
     - 集群管理。有机器死亡或新增，集群中其他机器需要感知到这种变化，然后根据这种变化做出对应的决策。
   - Zookeeper设计目的:
     - 最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。 
     - 可靠性：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。 
     - 实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。 
     - 原子性：更新只能成功或者失败，没有中间状态。 
     - 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。
     - 等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。感觉不是IFIO.
10. [Sqoop](https://github.com/sunnyandgood/BigData/blob/master/Sqoop/sqoop%E7%AE%80%E4%BB%8B.md)
11. HBase.
